#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
model_config.yaml - PCB缺陷檢測模型架構專用配置
整合模型架構參數、知識蒸餾策略和部署優化選項，
提供全面的模型配置方案。
"""

# 基礎模型架構設定 - 整合教師與學生模型的統一參數
architecture:
  input_shape: [416, 416, 3]  # [高, 寬, 通道]
  pretrained_backbone: true
  output_strides: [8, 16, 32]  # 不同特徵層的步長
  common_blocks: ["stem", "block1", "block2", "block3"] # 用於特徵層選擇和蒸餾參考

# 教師模型設定 - 強化性能，不考慮資源限制
teacher:
  model_type: "fasterrcnn"
  backbone: "resnet50"
  fpn:
    out_channels: 256
    extra_blocks: "lastlevel_maxpool"
  rpn:
    anchor_sizes: [32, 64, 128, 256, 512]
    aspect_ratios: [0.5, 1.0, 2.0]
    fg_iou_thresh: 0.7
    bg_iou_thresh: 0.3
    batch_size_per_image: 256
    positive_fraction: 0.5
  roi_heads:
    box_head_dim: 1024
    num_classes: 7  # 背景 + 6種缺陷
    score_thresh: 0.05
    nms_thresh: 0.5
    detections_per_img: 100
    fg_iou_thresh: 0.5
    bg_iou_thresh: 0.5
  loss_weights:
    rpn_cls: 1.0
    rpn_reg: 1.0
    box_cls: 1.0
    box_reg: 1.0

# 學生模型設定 - 輕量化設計，適合邊緣部署
student:
  model_type: "hybrid_detector"
  backbone: "mobilenetv3_small"
  channel_reduction_factor: 8  # 相比教師模型通道數的縮減倍數
  
  # 雙分支設定 - 全局與局部特徵提取
  dual_branch:
    enabled: true
    shared_backbone: true
    global_branch:
      fpn_channels: 96
      attention_type: "se"  # Squeeze-and-Excitation
    local_branch:
      fpn_channels: 96
      attention_type: "defect_specific"  # 缺陷特定注意力
  
  # 特徵提取頸部 - 輕量化FPN設計
  neck:
    type: "fpn"
    out_channels: 96
    extra_blocks: "lastlevel_p6p7"
    use_depthwise: true
    
  # 檢測頭設定 - 適應PCB小缺陷特點
  detection_head:
    anchor_sizes: [16, 32, 64, 128, 256]
    aspect_ratios: [0.5, 1.0, 2.0]
    num_classes: 7
    box_head_dim: 256
    use_group_norm: true
    share_box_predictor: false

# 知識蒸餾策略 - 多層次和多特徵蒸餾
distillation:
  kd_temperature: 3.0
  
  # 損失權重平衡
  loss_weights:
    task_loss: 0.5  # 檢測任務損失
    feature_loss: 0.3  # 特徵蒸餾損失
    logit_loss: 0.2  # 邏輯蒸餾損失
  
  # 特徵蒸餾設定
  feature_distillation:
    layers: [
      {"teacher": "layer1", "student": "features.3", "weight": 0.1},
      {"teacher": "layer2", "student": "features.6", "weight": 0.2},
      {"teacher": "layer3", "student": "features.9", "weight": 0.3}
    ]
    adaptation:
      type: "conv1x1"  # 特徵調整方法
      init_type: "kaiming"
    distance: "l2"  # 特徵距離度量
  
  # 策略調整 - 訓練過程中的動態調整
  schedule:
    initial_epochs: 10  # 純任務損失的預熱訓練
    rampup_epochs: 5  # 蒸餾權重逐步增加
    full_kd_epochs: 85  # 完整知識蒸餾訓練

# 注意力機制設定 - 針對不同缺陷類型優化
attention:
  common:
    reduction_ratio: 16
    use_spatial: true
  
  # 缺陷特定注意力參數
  defect_specific:
    Missing_hole:
      channel_weights: [0.3, 0.3, 0.4]  # RGB通道注意力權重
      spatial_kernel: 7  # 空間注意力核大小
    Mouse_bite:
      channel_weights: [0.25, 0.35, 0.4]
      spatial_kernel: 5
    Spur:
      channel_weights: [0.3, 0.4, 0.3]
      spatial_kernel: 5
    Spurious_copper:
      channel_weights: [0.3, 0.4, 0.3]
      spatial_kernel: 7
    Open_circuit:
      channel_weights: [0.25, 0.4, 0.35]
      spatial_kernel: 9
    Short:
      channel_weights: [0.3, 0.35, 0.35]
      spatial_kernel: 7

# 模型壓縮與優化 - 邊緣部署準備
optimization:
  # 量化設定
  quantization:
    method: "post_training"  # 訓練後量化
    precision: "int8"
    per_channel: true
    calibration_samples: 100
    bias_correction: true
  
  # 剪枝設定
  pruning:
    method: "magnitude"
    target_sparsity: 0.5
    schedule: "cubic"  # 剪枝調度
    granularity: "channel"  # 通道級剪枝
    exclude_layers: ["detection_head.classifier"]  # 不剪枝的層
  
  # 知識蒸餾後的額外優化
  post_distill:
    fine_tuning_epochs: 10
    learning_rate: 0.0001
    frozen_batch_norm: true